# README

## **Overview**
This repository implements a CNN-based solution for predicting various player attributes from sensor data. The code processes time-series data, builds CNN models for classification tasks, and evaluates their performance using metrics like ROC-AUC.

---

## **Setup**

### **Dependencies**
Ensure you have the following Python libraries installed:
- `numpy`
- `pandas`
- `tensorflow`
- `keras`
- `scikit-learn`
- `matplotlib`

Install all required libraries using:
```bash
pip install numpy pandas tensorflow keras scikit-learn matplotlib
```

---

## **Files**
- `train_data.csv`: Training features dataset.
- `train_info.csv`: Training labels for each player.
- `test_data.csv`: Test features dataset.

---

## **How to Run**

### **1. Prepare Data**
- **Input Files**: Place `train_data.csv`, `train_info.csv`, and `test_data.csv` in the working directory.
- **Preprocessing**:
  - Sensor data features (`Ax`, `Ay`, `Az`, `Gx`, `Gy`, `Gz`) are normalized using `StandardScaler`.
  - Each `data_id` group is converted into fixed-length sequences using padding or truncation.

### **2. Train Models**
Run the script directly:
```bash
python your_script_name.py
```

The script trains four separate CNN models:
1. **Gender Model**: Binary classification.
2. **Experience Model**: Multi-class classification for play years.
3. **Hand Model**: Binary classification for racket-handedness.
4. **Level Model**: Multi-class classification for player levels.

Each model is trained with:
- **Early Stopping**: Stops training if validation loss does not improve for a set number of epochs.
- **Learning Rate Scheduler**: Reduces learning rate when validation loss plateaus.

### **3. Evaluate Models**
The script computes validation metrics for each model:
- **ROC-AUC**
- **Accuracy**
- Additional metrics (e.g., precision, recall) can be added if needed.

### **4. Results**
The model evaluation summary is printed after training:
- **AUC Scores** for all models.
- Optionally, predictions for test data can be generated by extending the script.

---

## **Key Parameters**
- **Sequence Length**: Fixed to `1000` samples per `data_id`.
- **CNN Architecture**:
  - Five convolutional layers with kernel sizes of `3` or `5`.
  - `LeakyReLU` activation functions for non-linear transformations.
  - `GlobalAveragePooling1D` followed by dense layers.
- **Training Configuration**:
  - Epochs: `100`
  - Batch Size: `32`
  - Learning Rate: `0.001`

---

## **Customization**
- **Adjust Sequence Length**:
  Modify the `fixed_length` parameter in:
  ```python
  fixed_length = int(mid_range * 1000)
  ```
- **CNN Architecture**:
  Update the `create_cnn_model()` function to adjust layer configurations.
- **Evaluation Metrics**:
  Additional metrics can be included using `sklearn` or `tensorflow` utilities.

---

## **Output**
The script outputs:
1. **Validation Metrics**: Printed directly in the console.
2. **Test Predictions**: Extend the script to save predictions in CSV format.

---

## **Notes**
- Adjust `SEED` for reproducibility.
- If needed, enable GPU acceleration by ensuring `tensorflow-metal` (for macOS) or CUDA (for other platforms) is properly configured.
